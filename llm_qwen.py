# llm_qwen.py
# - Ollama(Qwen) í•´ì„¤ ìƒì„± (ê·¼ê±° JSONì€ LLMì´ ì°¸ê³ ë§Œ, í™”ë©´ì—ëŠ” ì¶œë ¥ ì•ˆ í•˜ë„ë¡ ìœ ë„)
# - í”„ë¡¬í”„íŠ¸(JSON) í¬ê¸° ì¤„ì´ê¸°(í•µì‹¬ ìŠ¤íƒ¯ë§Œ)ë¡œ ì†ë„/timeout ê°œì„ 
# - timeout(read) ê¸°ë³¸ 300ì´ˆë¡œ ìƒí–¥
# - ê¸°ë³¸ ëª¨ë¸: qwen2.5:3b

import json
import requests
import numpy as np
import pandas as pd


# =========================
# Helpers
# =========================
def _safe_float(x, default=0.0):
    try:
        if x is None:
            return default
        if isinstance(x, float) and np.isnan(x):
            return default
        return float(x)
    except Exception:
        return default


def _to_py(v):
    if isinstance(v, (np.integer, np.int64)):
        return int(v)
    if isinstance(v, (np.floating, np.float32, np.float64)):
        return float(v)
    return v


def _single_row_dict(row_df: pd.DataFrame) -> dict:
    r = row_df.iloc[0].to_dict()
    return {k: _to_py(v) for k, v in r.items()}


def _pick_name(row_dict: dict) -> str:
    for k in ["Name", "Player", "player_name", "ì„ ìˆ˜ëª…", "ì´ë¦„"]:
        if k in row_dict and row_dict[k] not in [None, ""]:
            return str(row_dict[k])
    return "ì„ ìˆ˜"


def _round_stat_map():
    return {
        "AVG": 3, "OBP": 3, "SLG": 3, "OPS": 3,
        "WAR": 2,
        "wRC_plus": 1, "wRC+": 1,
        "HR": 1, "H": 1, "RBI": 1, "SB": 1,
        "PA": 0,
    }


def _round_dict(d: dict) -> dict:
    rm = _round_stat_map()
    out = {}
    for k, v in (d or {}).items():
        base_k = k.replace("_next", "").replace("_delta", "")
        dec = rm.get(base_k, 3)
        try:
            out[k] = round(float(v), dec)
        except Exception:
            out[k] = v
    return out


# =========================
# Prompt size reducer (í•µì‹¬: JSON ì¤„ì´ê¸°)
# =========================
DEFAULT_LLM_STAT_COLS = ["OPS", "WAR", "wRC_plus", "AVG", "HR", "RBI", "PA"]


def _filter_stats_dict(d: dict, keep_cols) -> dict:
    if not isinstance(d, dict):
        return {}
    out = {}
    for k in keep_cols:
        if k in d:
            out[k] = d[k]
    return out


def _compact_career_series(series: list, keep_cols) -> list:
    if not isinstance(series, list):
        return []
    out = []
    for item in series:
        if not isinstance(item, dict):
            continue
        new_item = {"year": item.get("year")}
        for k in keep_cols:
            if k in item:
                new_item[k] = item[k]
        out.append(new_item)
    return out


def make_compact_context_for_llm(context: dict, keep_stat_cols=None) -> dict:
    """
    LLMì— ì „ë‹¬í•  contextë§Œ ì‘ê²Œ ë§Œë“ ë‹¤.
    - current/pred_next/pred_delta: keep_stat_colsë§Œ
    - career_recent: series/yoyë„ keep_stat_colsë§Œ
    - age_peers: mean/median/peer_yoy_mean_deltaë„ keep_stat_colsë§Œ
    """
    if keep_stat_cols is None:
        keep_stat_cols = DEFAULT_LLM_STAT_COLS

    ctx = json.loads(json.dumps(context, ensure_ascii=False, default=_to_py))

    # current / preds
    ctx["current"] = _filter_stats_dict(ctx.get("current", {}), keep_stat_cols)
    ctx["pred_next"] = _filter_stats_dict(ctx.get("pred_next", {}), keep_stat_cols)
    ctx["pred_delta"] = _filter_stats_dict(ctx.get("pred_delta", {}), keep_stat_cols)

    # career_recent
    cr = ctx.get("career_recent", {}) or {}
    if isinstance(cr, dict):
        cr["yoy_delta_base_vs_prev"] = _filter_stats_dict(cr.get("yoy_delta_base_vs_prev", {}), keep_stat_cols)
        cr["series"] = _compact_career_series(cr.get("series", []), keep_stat_cols)
        ctx["career_recent"] = cr

    # age_peers
    ap = ctx.get("age_peers", {}) or {}
    if isinstance(ap, dict):
        ap["mean"] = _filter_stats_dict(ap.get("mean", {}), keep_stat_cols)
        ap["median"] = _filter_stats_dict(ap.get("median", {}), keep_stat_cols)
        ap["peer_yoy_mean_delta"] = _filter_stats_dict(ap.get("peer_yoy_mean_delta", {}), keep_stat_cols)
        ctx["age_peers"] = ap

    # notesëŠ” ê¸¸ì–´ì§ˆ ìˆ˜ ìˆì–´ì„œ ì œê±°(ì›í•˜ë©´ ì£¼ì„ í•´ì œí•´ì„œ ìœ ì§€ ê°€ëŠ¥)
    ctx.pop("notes", None)

    return ctx


# =========================
# Context builders
# =========================
def build_career_context(
    df_all: pd.DataFrame,
    player_id,
    base_year: int,
    id_col="Id",
    year_col="Year",
    age_col="Age",
    team_col="Team",
    pa_col="PA",
    stat_cols=None,
    lookback=3,
):
    """
    ìµœê·¼ lookback ì‹œì¦Œì˜ ì‹œê³„ì—´ + base_year vs base_year-1 YoY Î”
    """
    if stat_cols is None:
        stat_cols = ["AVG", "OBP", "SLG", "OPS", "WAR", "wRC_plus", "HR", "H", "RBI", "SB", "PA"]

    me_all = df_all[df_all[id_col] == player_id].copy()
    if me_all.empty:
        return {}

    me_all[year_col] = pd.to_numeric(me_all[year_col], errors="coerce")
    me_all = me_all.dropna(subset=[year_col]).sort_values(year_col)

    me_hist = me_all[me_all[year_col].astype(int) <= int(base_year)].copy()
    if me_hist.empty:
        return {}

    years = sorted(me_hist[year_col].astype(int).unique().tolist())[-lookback:]
    me_hist = me_hist[me_hist[year_col].astype(int).isin(years)].sort_values(year_col)

    keep = []
    for c in ["Name", id_col, team_col, year_col, age_col, pa_col]:
        if c in me_hist.columns:
            keep.append(c)
    for c in stat_cols:
        if c in me_hist.columns and c not in keep:
            keep.append(c)

    me_hist = me_hist[keep].copy()

    for c in stat_cols:
        if c in me_hist.columns:
            me_hist[c] = pd.to_numeric(me_hist[c], errors="coerce")

    series = []
    for _, r in me_hist.iterrows():
        item = {"year": int(r[year_col])}
        for c in stat_cols:
            if c in me_hist.columns:
                item[c] = _to_py(r.get(c, None))
        series.append(item)

    yoy = {}
    prev_year = int(base_year) - 1
    base_row = me_all[me_all[year_col].astype(int) == int(base_year)]
    prev_row = me_all[me_all[year_col].astype(int) == int(prev_year)]
    if (not base_row.empty) and (not prev_row.empty):
        b = base_row.iloc[0]
        p = prev_row.iloc[0]
        for c in stat_cols:
            if c in me_all.columns:
                bv = pd.to_numeric(b.get(c, np.nan), errors="coerce")
                pv = pd.to_numeric(p.get(c, np.nan), errors="coerce")
                if pd.notna(bv) and pd.notna(pv):
                    yoy[c] = float(bv - pv)

    return {
        "available_years": years,
        "series": series,
        "yoy_delta_base_vs_prev": yoy,
    }


def build_age_peer_context(
    df_all: pd.DataFrame,
    player_id,
    base_year: int,
    id_col="Id",
    year_col="Year",
    age_col="Age",
    team_col="Team",
    pa_col="PA",
    stat_cols=None,
    age_band=1,
    pa_min=223,
    same_team_only=False,
    include_peer_yoy=True,
):
    """
    ë™ë‚˜ì´ëŒ€(Â±age_band) ì§‘ë‹¨ ìš”ì•½ (base_year ë™ì¼, PA>=pa_min)
    + (ì˜µì…˜) peer_yoy_mean_delta: (base_year - base_year-1) í‰ê·  Î”
    """
    if stat_cols is None:
        stat_cols = ["AVG", "OBP", "SLG", "OPS", "WAR", "wRC_plus", "HR", "H", "RBI", "SB", "PA"]

    df = df_all.copy()
    df[year_col] = pd.to_numeric(df[year_col], errors="coerce")
    df[age_col] = pd.to_numeric(df[age_col], errors="coerce")
    df[pa_col] = pd.to_numeric(df[pa_col], errors="coerce")

    me = df[(df[id_col] == player_id) & (df[year_col].astype(int) == int(base_year))].copy()
    if me.empty:
        return {}

    my_age = _safe_float(me.iloc[0].get(age_col, np.nan), default=np.nan)
    my_team = str(me.iloc[0].get(team_col, ""))

    peers = df[df[year_col].astype(int) == int(base_year)].copy()

    if not np.isnan(my_age):
        peers = peers[(peers[age_col] >= my_age - age_band) & (peers[age_col] <= my_age + age_band)]

    peers = peers[peers[pa_col] >= float(pa_min)]

    if same_team_only and team_col in peers.columns:
        peers = peers[peers[team_col].astype(str) == my_team]

    for c in stat_cols:
        if c in peers.columns:
            peers[c] = pd.to_numeric(peers[c], errors="coerce")

    numeric_cols = [c for c in stat_cols if c in peers.columns]

    out = {
        "definition": f"base_year ë™ì¼, ë‚˜ì´Â±{age_band}ì„¸, PA>={pa_min}" + (", ê°™ì€ íŒ€" if same_team_only else ""),
        "count": int(peers[id_col].nunique()) if id_col in peers.columns else int(len(peers)),
    }

    if not peers.empty and numeric_cols:
        out["mean"] = peers[numeric_cols].mean(numeric_only=True).to_dict()
        out["median"] = peers[numeric_cols].median(numeric_only=True).to_dict()

    if include_peer_yoy:
        prev_year = int(base_year) - 1
        df_prev = df[df[year_col].astype(int) == prev_year].copy()

        peer_ids = set(peers[id_col].dropna().tolist())
        df_base_peer = df[(df[year_col].astype(int) == int(base_year)) & (df[id_col].isin(peer_ids))].copy()
        df_prev_peer = df_prev[df_prev[id_col].isin(peer_ids)].copy()

        base_keep = [id_col] + [c for c in numeric_cols if c in df_base_peer.columns]
        prev_keep = [id_col] + [c for c in numeric_cols if c in df_prev_peer.columns]
        dfb = df_base_peer[base_keep].copy()
        dfp = df_prev_peer[prev_keep].copy()

        for c in numeric_cols:
            if c in dfb.columns:
                dfb[c] = pd.to_numeric(dfb[c], errors="coerce")
            if c in dfp.columns:
                dfp[c] = pd.to_numeric(dfp[c], errors="coerce")

        merged = pd.merge(dfb, dfp, on=id_col, suffixes=("_b", "_p"))
        if not merged.empty:
            deltas = {}
            for c in numeric_cols:
                cb = f"{c}_b"
                cp = f"{c}_p"
                if cb in merged.columns and cp in merged.columns:
                    diff = merged[cb] - merged[cp]
                    deltas[c] = float(diff.mean(skipna=True))
            out["peer_yoy_mean_delta"] = deltas

    return out


# =========================
# Prompt
# =========================
def build_explain_prompt(context: dict) -> str:
    # âœ… LLMì— ì „ë‹¬í•˜ëŠ” ê·¼ê±° contextë¥¼ "ì‘ê²Œ" ë§Œë“ ë‹¤
    ctx = make_compact_context_for_llm(context, keep_stat_cols=DEFAULT_LLM_STAT_COLS)

    # round for readability
    for key in ["current", "pred_next", "pred_delta"]:
        if key in ctx and isinstance(ctx[key], dict):
            ctx[key] = _round_dict(ctx[key])

    if "career_recent" in ctx and isinstance(ctx["career_recent"], dict):
        if "yoy_delta_base_vs_prev" in ctx["career_recent"]:
            ctx["career_recent"]["yoy_delta_base_vs_prev"] = _round_dict(ctx["career_recent"]["yoy_delta_base_vs_prev"])

    if "age_peers" in ctx and isinstance(ctx["age_peers"], dict):
        if "mean" in ctx["age_peers"]:
            ctx["age_peers"]["mean"] = _round_dict(ctx["age_peers"]["mean"])
        if "median" in ctx["age_peers"]:
            ctx["age_peers"]["median"] = _round_dict(ctx["age_peers"]["median"])
        if "peer_yoy_mean_delta" in ctx["age_peers"]:
            ctx["age_peers"]["peer_yoy_mean_delta"] = _round_dict(ctx["age_peers"]["peer_yoy_mean_delta"])

    # âœ… JSONì„ "ì••ì¶•"í•´ì„œ í† í°/ì‹œê°„ ì ˆì•½
    context_json = json.dumps(ctx, ensure_ascii=False, separators=(",", ":"))

    return f"""ë„ˆëŠ” KBO íƒ€ì ì„±ì  ì˜ˆì¸¡(Î”ëª¨ë¸) ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ëŠ” ë°ì´í„° ë¶„ì„ê°€ë‹¤.
ë°˜ë“œì‹œ [ê·¼ê±° JSON]ì— í¬í•¨ëœ ìˆ«ìì™€ ì‚¬ì‹¤ë§Œ ì‚¬ìš©í•´ì„œ í•´ì„¤í•´ë¼.
ë¶€ìƒ/ë©˜íƒˆ/ì½”ì¹˜/íŠ¸ë ˆì´ë“œ/ì»¨ë””ì…˜/íƒ€êµ¬ì§ˆ ê°™ì€ ì™¸ë¶€ ìš”ì¸ì€ ê·¼ê±° JSONì— ì—†ìœ¼ë©´ ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆë¼.

ğŸš« ë§¤ìš° ì¤‘ìš”(ì¶œë ¥ ì œí•œ):
- ê·¼ê±° JSON(ì›ë¬¸)ì„ ì ˆëŒ€ë¡œ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆë¼.
- JSON/ì½”ë“œë¸”ë¡/```/ê´„í˜¸ {{}} í˜•íƒœë¡œ ì¬ì¶œë ¥ ê¸ˆì§€.
- ì¶œë ¥ì—ëŠ” "ê·¼ê±° JSON", "JSON", "context_json" ê°™ì€ ë‹¨ì–´ë„ ì“°ì§€ ë§ˆë¼.
- ìˆ«ìëŠ” ë¬¸ì¥ ì†ì— ë…¹ì—¬ì„œ ì„¤ëª…ë§Œ í•´ë¼.

[ì¶œë ¥ í˜•ì‹]
- í•œêµ­ì–´ 8~12ë¬¸ì¥
- ë¬¸ì¥í˜• ì„œìˆ ë¡œ ì‘ì„±(í‘œ/ì½”ë“œ/ë¶ˆë¦¿ ê¸ˆì§€)
- ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ:
  1) í•œ ì¤„ ê²°ë¡ : â€œë‹¤ìŒ ì‹œì¦Œì€ ì „ë…„ ëŒ€ë¹„ â—‹â—‹ ë°©í–¥(ìƒìŠ¹/í•˜ë½/ìœ ì§€)ìœ¼ë¡œ ì˜ˆì¸¡â€ (OPS/WAR ì¤‘ì‹¬)
  2) ì „ë…„ë„(base_year)ì˜ í˜„ì¬ ìŠ¤íƒ¯ê³¼ ì˜ˆì¸¡(next), ê·¸ë¦¬ê³  Î”(ì¦ê°) ì—°ê²° ì„¤ëª…
  3) ì»¤ë¦¬ì–´ íë¦„(ìµœê·¼ Në…„): ìµœê·¼ 2~3ë…„ì˜ ë³€í™”ê°€ ì˜ˆì¸¡ì— ì–´ë–»ê²Œ ë°˜ì˜ëëŠ”ì§€
  4) ë™ë‚˜ì´ëŒ€ ë¹„êµ: ë™ë‚˜ì´ëŒ€(Â±1ì„¸) ì§‘ë‹¨ í‰ê· /ì¤‘ì•™ê°’ê³¼ ë¹„êµí•´ì„œ â€œí‰ê·  ëŒ€ë¹„ ì–´ë–¤ í¸ì¸ì§€â€
  5) PA(íƒ€ì„) ë³€í™”ê°€ ì˜ˆì¸¡ í•´ì„ì— ì£¼ëŠ” ì˜ë¯¸(í‘œë³¸/ì¶œì „ê¸°íšŒ ê´€ì ) â€” ë‹¨, ê·¼ê±° JSON ìˆ˜ì¹˜ë¡œë§Œ
  6) ë§ˆì§€ë§‰ ë¬¸ì¥ì— â€œì°¸ê³ ìš©â€ ì•ˆë‚´

[í•´ì„¤ ê·œì¹™]
- OPS, WAR, wRC+ë¥¼ ìš°ì„ ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , HR/RBI/AVGëŠ” ë³´ì¡°ë¡œ ì‚¬ìš©
- â€œë™ë‚˜ì´ëŒ€ í‰ê· ì ì¸ aging trend(ì¦ê°)â€ê³¼ â€œì„ ìˆ˜ ê°œì¸ ì»¤ë¦¬ì–´ trend(ì¦ê°)â€ì´
  ê°™ì€ ë°©í–¥ì´ë©´ â€œì¶”ì„¸ ì¼ì¹˜â€, ë°˜ëŒ€ë©´ â€œì¶”ì„¸ ì—­í–‰/ìƒì‡„â€ë¡œ í‘œí˜„í•´ë¼.
- ìˆ«ìëŠ” AVG/OPS 3ìë¦¬, WAR 2ìë¦¬, wRC+ 1ìë¦¬, PAëŠ” ì •ìˆ˜ë¡œ ë§í•´ë¼.

[ê·¼ê±° JSON]
{context_json}
"""


# =========================
# Ollama client
# =========================
def ollama_chat(
    prompt: str,
    model: str = "qwen2.5:3b",
    base_url: str = "http://localhost:11434",
    temperature: float = 0.4,
    top_p: float = 0.9,
    timeout: int = 300,  # âœ… read timeout ê¸°ë³¸ 300ì´ˆ
) -> str:
    """
    - LLMì€ ê·¼ê±° JSONì„ ì°¸ê³ í•˜ì§€ë§Œ
    - ì‘ë‹µì€ ìŠ¤í‚¤ë§ˆ(format)ë¡œ ê°•ì œí•´ì„œ "text"ë§Œ ëŒë ¤ë°›ë„ë¡ ì‹œë„
    """
    url = base_url.rstrip("/") + "/api/chat"

    payload = {
        "model": model,
        "stream": False,
        "messages": [
            {"role": "system", "content": "ë„ˆëŠ” ì•¼êµ¬ ë°ì´í„° í•´ì„¤ì„ ê·¼ê±° ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¶„ì„ê°€ë‹¤."},
            {"role": "user", "content": prompt},
        ],
        "options": {"temperature": temperature, "top_p": top_p},
        # âœ… ì¶œë ¥ í˜•ì‹ ê°•ì œ (í™˜ê²½/ë²„ì „ì— ë”°ë¼ ë¬´ì‹œë  ìˆ˜ë„ ìˆìŒ)
        "format": {
            "type": "object",
            "properties": {"text": {"type": "string"}},
            "required": ["text"],
        },
    }

    # âœ… connect=10ì´ˆ, read=timeoutì´ˆ
    r = requests.post(url, json=payload, timeout=(10, timeout))
    r.raise_for_status()
    data = r.json()

    content = (data.get("message", {}) or {}).get("content", "") or ""
    content = content.strip()

    # formatì´ ë¨¹ìœ¼ë©´ contentê°€ JSON ë¬¸ìì—´ë¡œ ì˜¬ ê°€ëŠ¥ì„± í¼ -> textë§Œ ë½‘ê¸°
    try:
        parsed = json.loads(content)
        if isinstance(parsed, dict) and "text" in parsed:
            return str(parsed["text"]).strip()
    except Exception:
        pass

    # ë³´í—˜: í˜¹ì‹œ ëª¨ë¸ì´ ê·¼ê±° ë¸”ë¡ì„ ì¶œë ¥í•˜ë©´ ì˜ë¼ë²„ë¦¼
    marker = "[ê·¼ê±° JSON]"
    if marker in content:
        content = content.split(marker, 1)[0].strip()

    return content


def generate_explanation(
    df_all: pd.DataFrame,
    row_df: pd.DataFrame,
    next_pred: dict,
    delta_pred: dict,
    player_id,
    base_year: int,
    pred_year: int,
    id_col="Id",
    year_col="Year",
    age_col="Age",
    team_col="Team",
    pa_col="PA",
    stat_cols=None,
    age_band=1,
    pa_min=223,
    same_team_only=False,
    model_name: str = "qwen2.5:3b",
    base_url: str = "http://localhost:11434",
    return_context: bool = False,  # âœ… ê¸°ë³¸: ë””ë²„ê·¸ context ë°˜í™˜ ì•ˆ í•¨
    llm_timeout: int = 300,         # âœ… í•„ìš”í•˜ë©´ ì—¬ê¸°ë§Œ ëŠ˜ë¦¬ë©´ ë¨
) -> tuple[str, dict | None]:
    """
    ë°˜í™˜:
      - explanation_text
      - context_used (ë””ë²„ê·¸ìš©)  -> return_context=Trueì¼ ë•Œë§Œ
    """
    if stat_cols is None:
        stat_cols = ["AVG", "OBP", "SLG", "OPS", "WAR", "wRC_plus", "HR", "H", "RBI", "SB", "PA"]

    row_dict = _single_row_dict(row_df)
    player_name = _pick_name(row_dict)
    team = str(row_dict.get(team_col, ""))

    current = {}
    for c in stat_cols:
        if c in row_df.columns:
            current[c] = _safe_float(row_df.iloc[0].get(c, np.nan), default=np.nan)

    career_recent = build_career_context(
        df_all=df_all,
        player_id=player_id,
        base_year=base_year,
        id_col=id_col,
        year_col=year_col,
        age_col=age_col,
        team_col=team_col,
        pa_col=pa_col,
        stat_cols=stat_cols,
        lookback=3,
    )

    age_peers = build_age_peer_context(
        df_all=df_all,
        player_id=player_id,
        base_year=base_year,
        id_col=id_col,
        year_col=year_col,
        age_col=age_col,
        team_col=team_col,
        pa_col=pa_col,
        stat_cols=stat_cols,
        age_band=age_band,
        pa_min=pa_min,
        same_team_only=same_team_only,
        include_peer_yoy=True,
    )

    context = {
        "player": {"id": _to_py(player_id), "name": player_name, "team": team},
        "season": {
            "base_year": int(base_year),
            "pred_year": int(pred_year),
            "age": _to_py(row_dict.get(age_col, None)),
            "pa_min_policy": int(pa_min),
            "peer_age_band": int(age_band),
            "peer_same_team_only": bool(same_team_only),
        },
        "current": current,
        "pred_delta": delta_pred,
        "pred_next": next_pred,
        "career_recent": career_recent,
        "age_peers": age_peers,
        "notes": {
            "explain_policy": "ê·¼ê±° JSON ìˆ«ìë§Œ ì‚¬ìš©, ì™¸ë¶€ ìš”ì¸ ì¶”ì¸¡ ê¸ˆì§€",
            "model_type": "delta_model (next = current + delta)",
        },
    }

    prompt = build_explain_prompt(context)
    text = ollama_chat(
        prompt=prompt,
        model=model_name,
        base_url=base_url,
        temperature=0.4,
        top_p=0.9,
        timeout=llm_timeout,
    )

    return text, (context if return_context else None)
