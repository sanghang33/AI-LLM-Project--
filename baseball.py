# app.py
import os
import joblib
import numpy as np
import pandas as pd
import streamlit as st
import requests
from tensorflow import keras

# =========================================================
# LLM (Qwen / Ollama) Fixed Config
# =========================================================
LLM_MODEL = "qwen2.5:3b"
OLLAMA_URL = "http://localhost:11434"

try:
    from llm_qwen import generate_explanation
    LLM_IMPORT_OK = True
    LLM_IMPORT_ERR = ""
except Exception as _e:
    generate_explanation = None
    LLM_IMPORT_OK = False
    LLM_IMPORT_ERR = str(_e)

# =========================================================
# Page
# =========================================================
st.set_page_config(page_title="KBO Next Season Predictor (Î”)", layout="wide")
st.title("âš¾ KBO ë‹¤ìŒ ì‹œì¦Œ ì„±ì  ì˜ˆì¸¡")

# =========================================================
# Paths
# =========================================================
DEFAULT_CSV = r"C:\Users\yusan\OneDrive\Desktop\2025 winter\Notebook\Colab Notebooks\dataset\kbo_batting_stats.csv"

MODEL_DIR = "model_kbo"
MODEL_PATH = os.path.join(MODEL_DIR, "kbo_mlp.keras")
IMPUTER_PATH = os.path.join(MODEL_DIR, "imputer.pkl")
X_SCALER_PATH = os.path.join(MODEL_DIR, "x_scaler.pkl")
Y_SCALER_PATH = os.path.join(MODEL_DIR, "y_scaler.pkl")
FEATURE_COLS_PATH = os.path.join(MODEL_DIR, "feature_cols.pkl")
TARGETS_PATH = os.path.join(MODEL_DIR, "targets.pkl")
META_PATH = os.path.join(MODEL_DIR, "meta.pkl")

# =========================================================
# Column names
# =========================================================
ID_COL = "Id"
YEAR_COL = "Year"
AGE_COL = "Age"
TEAM_COL = "Team"
PA_COL = "PA"
NAME_CANDIDATES = ["Name", "Player", "player_name", "ì„ ìˆ˜ëª…", "ì´ë¦„"]

# =========================================================
# ì •ì±…(í•„í„°/ê·œì¹™)
# =========================================================
FILTER_TEAM_YEAR = 2025
DEBUT_MIN_YEAR = 2000
PA_MIN_PRED = 223  # âœ… base_year PA ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨

# =========================================================
# Utils / Load
# =========================================================
@st.cache_resource
def load_bundle():
    needed = [
        MODEL_PATH,
        IMPUTER_PATH,
        X_SCALER_PATH,
        Y_SCALER_PATH,
        FEATURE_COLS_PATH,
        TARGETS_PATH,
        META_PATH,
    ]
    missing = [p for p in needed if not os.path.exists(p)]
    if missing:
        raise FileNotFoundError(
            "ëª¨ë¸ ë²ˆë“¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (model_kbo í´ë” í™•ì¸)\n"
            f"ëˆ„ë½: {missing}"
        )

    model = keras.models.load_model(MODEL_PATH)
    imputer = joblib.load(IMPUTER_PATH)
    x_scaler = joblib.load(X_SCALER_PATH)
    y_scaler = joblib.load(Y_SCALER_PATH)
    feature_cols = joblib.load(FEATURE_COLS_PATH)
    display_targets = joblib.load(TARGETS_PATH)
    meta = joblib.load(META_PATH)

    if meta.get("mode") != "delta":
        raise ValueError(f"meta.pklì˜ modeê°€ deltaê°€ ì•„ë‹™ë‹ˆë‹¤: {meta.get('mode')}")

    return model, imputer, x_scaler, y_scaler, feature_cols, display_targets, meta


@st.cache_data
def load_and_prepare_csv(csv_path: str, meta: dict, feature_cols: list[str]) -> pd.DataFrame:
    df = pd.read_csv(csv_path)
    df = df.rename(columns={"wRC+": "wRC_plus"})

    need = [ID_COL, YEAR_COL, AGE_COL, PA_COL]
    missing = [c for c in need if c not in df.columns]
    if missing:
        raise ValueError(f"CSVì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}\ní˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")

    name_col = None
    for c in NAME_CANDIDATES:
        if c in df.columns:
            name_col = c
            break
    if name_col and name_col != "Name":
        df["Name"] = df[name_col]

    df[YEAR_COL] = pd.to_numeric(df[YEAR_COL], errors="coerce")
    df[AGE_COL] = pd.to_numeric(df[AGE_COL], errors="coerce")
    df[PA_COL] = pd.to_numeric(df[PA_COL], errors="coerce")

    base_targets = meta.get("targets", [])
    for t in base_targets:
        if t in df.columns:
            df[t] = pd.to_numeric(df[t], errors="coerce")

    df = df.sort_values([ID_COL, YEAR_COL]).reset_index(drop=True)

    df["Age2"] = df[AGE_COL] ** 2

    if f"{PA_COL}_prev" not in df.columns:
        df[f"{PA_COL}_prev"] = df.groupby(ID_COL)[PA_COL].shift(1)

    for t in base_targets:
        prev_col = f"{t}_prev"
        if prev_col not in df.columns and t in df.columns:
            df[prev_col] = df.groupby(ID_COL)[t].shift(1)

    for c in feature_cols:
        if c not in df.columns:
            df[c] = np.nan

    return df


def predict_next_from_row(model, imputer, x_scaler, y_scaler, row_df: pd.DataFrame, feature_cols: list[str], meta: dict):
    x_raw = row_df[feature_cols].copy().fillna(0.0)
    x_imp = imputer.transform(x_raw.values.astype("float32"))
    x = x_scaler.transform(x_imp).astype("float32")

    delta_s = model.predict(x, verbose=0)
    delta = y_scaler.inverse_transform(delta_s)[0]

    delta_targets = meta["delta_targets"]
    current_cols = meta["current_cols"]
    next_names = meta["next_names"]

    delta_pred = dict(zip(delta_targets, [float(v) for v in delta]))

    cur = np.array([float(row_df.iloc[0][c]) for c in current_cols], dtype="float32")
    next_pred_arr = cur + delta.astype("float32")
    next_pred_arr[-1] = max(0.0, float(next_pred_arr[-1]))

    next_pred = dict(zip(next_names, [float(v) for v in next_pred_arr]))
    return next_pred, delta_pred


def pretty_table_next(next_pred: dict):
    out_next = pd.DataFrame([{"Target": k, "Predicted": v} for k, v in next_pred.items()])
    round_map = {
        "AVG_next": 3, "OBP_next": 3, "SLG_next": 3, "OPS_next": 3,
        "WAR_next": 3, "wRC_plus_next": 1,
        "HR_next": 1, "H_next": 1, "RBI_next": 1, "SB_next": 1,
        "PA_next": 0,
    }

    def _round(k, v):
        return round(v, round_map.get(k, 3))

    out_next["Predicted"] = out_next.apply(lambda r: _round(r["Target"], r["Predicted"]), axis=1)

    key_order = [t for t in ["HR_next", "H_next", "RBI_next", "AVG_next", "OPS_next", "WAR_next", "wRC_plus_next", "PA_next"]
                 if t in out_next["Target"].values]
    key_out = out_next[out_next["Target"].isin(key_order)].copy()
    rest_out = out_next[~out_next["Target"].isin(key_order)].copy()

    return key_out, pd.concat([key_out, rest_out], ignore_index=True)


def pretty_table_delta(delta_pred: dict):
    out_delta = pd.DataFrame([{"Target": k, "Delta": v} for k, v in delta_pred.items()])
    d_round_map = {
        "AVG_delta": 3, "OBP_delta": 3, "SLG_delta": 3, "OPS_delta": 3,
        "WAR_delta": 2, "wRC_plus_delta": 1,
        "HR_delta": 1, "H_delta": 1, "RBI_delta": 1, "SB_delta": 1,
        "PA_delta": 0,
    }
    out_delta["Delta"] = out_delta.apply(lambda r: round(r["Delta"], d_round_map.get(r["Target"], 3)), axis=1)
    return out_delta


def map_next_delta_to_base(next_pred: dict, delta_pred: dict):
    pred_next = {k.replace("_next", ""): float(v) for k, v in next_pred.items()}
    pred_delta = {k.replace("_delta", ""): float(v) for k, v in delta_pred.items()}
    return pred_next, pred_delta


# =========================================================
# Sidebar
# =========================================================
with st.sidebar:
    st.header("ì„¤ì •")
    csv_path = st.text_input("ë°ì´í„° CSV ê²½ë¡œ", value=DEFAULT_CSV)
    show_raw = st.checkbox("ê¸°ì¤€ë…„ë„ ì›ë³¸ ìŠ¤íƒ¯(ì…ë ¥ row) í‘œì‹œ", value=True)
    show_delta = st.checkbox("ì¦ê°(Î”)ë„ ê°™ì´ ë³´ê¸°", value=False)

    st.divider()
    st.header("í•„í„°/ì •ì±…")
    st.caption(f"âœ… ë°ë·” {DEBUT_MIN_YEAR}ë…„ ì´ìƒ ì„ ìˆ˜ë§Œ í‘œì‹œ")
    st.caption(f"âœ… íŒ€ í•„í„°ëŠ” {FILTER_TEAM_YEAR}ë…„ ì‹œì¦Œ ì†Œì† ê¸°ì¤€")
    st.caption(f"âœ… ì˜ˆì¸¡ ê°€ëŠ¥(ì‹œì¦Œ ê¸°ì¤€): base_year PA â‰¥ {PA_MIN_PRED}")
    st.caption("âœ… Î”ëª¨ë¸: next = current + delta")


# =========================================================
# Load bundle
# =========================================================
try:
    model, imputer, x_scaler, y_scaler, feature_cols, display_targets, meta = load_bundle()
except Exception as e:
    st.error(str(e))
    st.stop()

TRAIN_MIN_YEAR = int(meta.get("train_min_year", 2015))

# =========================================================
# Load data
# =========================================================
try:
    df = load_and_prepare_csv(csv_path, meta, feature_cols)
except Exception as e:
    st.error(f"CSV ë¡œë“œ/ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    st.stop()

missing_feat = [c for c in feature_cols if c not in df.columns]
if missing_feat:
    st.error("CSVì— feature ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤:\n" f"{missing_feat}\n\n" f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
    st.stop()

# =========================================================
# Filters: Debut >= 2000
# =========================================================
debut_year_by_player = df.groupby(ID_COL)[YEAR_COL].min().dropna().astype(int)
eligible_ids = set(debut_year_by_player[debut_year_by_player >= int(DEBUT_MIN_YEAR)].index)

# =========================================================
# Team filter based on roster in 2025
# =========================================================
st.subheader("1) íŒ€ / ì„ ìˆ˜ / ê¸°ì¤€ë…„ë„ ì„ íƒ")

if TEAM_COL not in df.columns:
    st.error("CSVì— Team ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒ€ í•„í„°ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Team ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

teams_2025 = (
    df.loc[df[YEAR_COL].astype("Int64") == int(FILTER_TEAM_YEAR), TEAM_COL]
    .dropna().astype(str).sort_values().unique().tolist()
)

if not teams_2025:
    st.error(f"{FILTER_TEAM_YEAR}ë…„ ì‹œì¦Œ ë°ì´í„°ì—ì„œ Team ê°’ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (Year/Team ì»¬ëŸ¼ í™•ì¸)")
    st.stop()

selected_team = st.selectbox("íŒ€ ì„ íƒ (2025ë…„ ê¸°ì¤€)", options=["(ì „ì²´)"] + teams_2025, index=0)

if selected_team != "(ì „ì²´)":
    ids_in_team_2025 = set(
        df.loc[
            (df[YEAR_COL].astype("Int64") == int(FILTER_TEAM_YEAR)) &
            (df[TEAM_COL].astype(str) == str(selected_team)),
            ID_COL
        ].dropna().tolist()
    )
    eligible_ids = eligible_ids.intersection(ids_in_team_2025)

df_filtered = df[df[ID_COL].isin(list(eligible_ids))].copy()

st.caption(
    f"í•„í„°: ë°ë·”>= {DEBUT_MIN_YEAR}"
    + (f", 2025íŒ€={selected_team}" if selected_team != "(ì „ì²´)" else ", 2025íŒ€=ì „ì²´")
    + f" | ì„ ìˆ˜ ìˆ˜: {df_filtered[ID_COL].nunique()}"
)

if df_filtered.empty:
    st.warning("í•„í„° ì¡°ê±´ì— ë§ëŠ” ì„ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. íŒ€ì„ (ì „ì²´)ë¡œ ë°”ê¾¸ê±°ë‚˜ ì¡°ê±´ì„ ì™„í™”í•˜ì„¸ìš”.")
    st.stop()

# =========================================================
# Player select
# =========================================================
if "Name" in df_filtered.columns:
    players = df_filtered[[ID_COL, "Name"]].drop_duplicates().copy()
else:
    players = df_filtered[[ID_COL]].drop_duplicates().copy()

players = players.sort_values(["Name"] if "Name" in players.columns else [ID_COL])
player_options = players["Name"].fillna("ì„ ìˆ˜").tolist() if "Name" in players.columns else players[ID_COL].astype(str).tolist()
player_ids = players[ID_COL].tolist()

sel_idx = st.selectbox(
    "ì„ ìˆ˜ ì„ íƒ",
    options=list(range(len(player_options))),
    format_func=lambda i: player_options[i],
)
player_id = player_ids[sel_idx]

# =========================================================
# Base year select
# =========================================================
years = (
    df_filtered.loc[(df_filtered[ID_COL] == player_id) & (df_filtered[YEAR_COL] >= TRAIN_MIN_YEAR), YEAR_COL]
    .dropna().astype(int).sort_values().unique().tolist()
)
if not years:
    st.warning(f"ì„ íƒí•œ ì„ ìˆ˜ì— ëŒ€í•´ {TRAIN_MIN_YEAR}ë…„ ì´í›„ Year ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

base_year = st.selectbox("ê¸°ì¤€ë…„ë„(base_year) ì„ íƒ", options=years, index=len(years) - 1)
pred_year = int(base_year) + 1

row = df_filtered[(df_filtered[ID_COL] == player_id) & (df_filtered[YEAR_COL].astype(int) == int(base_year))].copy()
if len(row) != 1:
    st.error(f"ì„ íƒí•œ ì„ ìˆ˜/ì—°ë„ í–‰ì„ 1ê°œë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ê°œìˆ˜={len(row)})")
    st.stop()

base_pa = float(row.iloc[0].get(PA_COL, 0.0) or 0.0)
is_predictable = (base_pa >= PA_MIN_PRED)

st.caption(
    f"ì„ íƒ ì‹œì¦Œ ì •ë³´: base_year={base_year}, PA={base_pa:.0f} | "
    f"ì˜ˆì¸¡ ê°€ëŠ¥ ì¡°ê±´: PA â‰¥ {PA_MIN_PRED} => {'âœ… ê°€ëŠ¥' if is_predictable else 'âŒ ë¶ˆê°€'}"
)

# =========================================================
# Predict
# =========================================================
st.subheader("2) ì˜ˆì¸¡ ì‹¤í–‰")
run = st.button("ğŸš€ ë‹¤ìŒ ì‹œì¦Œ ì˜ˆì¸¡í•˜ê¸°", use_container_width=True)

if run:
    if not is_predictable:
        st.error(f"ì˜ˆì¸¡ ë¶ˆê°€: {base_year}ë…„ PA < {PA_MIN_PRED} (í‘œë³¸ ë¶€ì¡±)")
        st.stop()

    next_pred, delta_pred = predict_next_from_row(model, imputer, x_scaler, y_scaler, row, feature_cols, meta)

    st.success(f"ì˜ˆì¸¡ ì™„ë£Œ! (ê¸°ì¤€ {base_year} â†’ ì˜ˆì¸¡ {pred_year})")

    key_out, full_out = pretty_table_next(next_pred)

    if show_raw:
        st.markdown("### ğŸ“Œ ê¸°ì¤€ë…„ë„ ì›ë³¸ ìŠ¤íƒ¯")
        raw_cols = [c for c in ["Name", ID_COL, TEAM_COL, YEAR_COL, PA_COL] + feature_cols if c in row.columns]
        raw_cols = list(dict.fromkeys(raw_cols))
        raw_cols = [c for c in raw_cols if not c.endswith("_prev")]

        st.dataframe(row[raw_cols], use_container_width=True, hide_index=True)


    st.markdown("### â­ í•µì‹¬ ì˜ˆì¸¡ ê²°ê³¼")
    st.dataframe(key_out, use_container_width=True, hide_index=True)

    with st.expander("ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ë³´ê¸°"):
        st.dataframe(full_out, use_container_width=True, hide_index=True)

    if show_delta:
        st.markdown("### ğŸ” ì˜ˆì¸¡ëœ ì¦ê°(Î”)")
        st.dataframe(pretty_table_delta(delta_pred), use_container_width=True, hide_index=True)


    # =========================================================
    # âœ… ìë™ LLM í•´ì„¤ (ë²„íŠ¼ ì—†ì´ ë°”ë¡œ ìƒì„±/í‘œì‹œ)
    # =========================================================
    st.markdown("### ğŸ§  ì˜ˆì¸¡ ì´ìœ  (LLM í•´ì„¤)")

    if not LLM_IMPORT_OK:
        st.info("LLM ê¸°ëŠ¥ì„ ì“°ë ¤ë©´ ê°™ì€ í´ë”ì— llm_qwen.pyê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        with st.expander("import ì—ëŸ¬ ë³´ê¸°"):
            st.code(LLM_IMPORT_ERR)
    else:
        out_key = f"auto_reason_text_{player_id}_{base_year}"
        ctx_key = f"auto_reason_ctx_{player_id}_{base_year}"
        reason_box = st.empty()

        # ì´ë¯¸ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
        if out_key in st.session_state and st.session_state[out_key]:
            reason_box.markdown(st.session_state[out_key])
        else:
            pred_next_base, pred_delta_base = map_next_delta_to_base(next_pred, delta_pred)
            default_stat_cols = ["AVG", "OBP", "SLG", "OPS", "WAR", "wRC_plus", "HR", "H", "RBI", "SB", "PA"]
            stat_cols = [c for c in default_stat_cols if c in df_filtered.columns]

            with st.spinner("Qwenì´ ì˜ˆì¸¡ ì´ìœ ë¥¼ ìƒì„± ì¤‘..."):
                try:
                    explanation, ctx_used = generate_explanation(
                        df_all=df_filtered,
                        row_df=row,
                        next_pred=pred_next_base,
                        delta_pred=pred_delta_base,
                        player_id=player_id,
                        base_year=int(base_year),
                        pred_year=int(pred_year),
                        id_col=ID_COL,
                        year_col=YEAR_COL,
                        age_col=AGE_COL,
                        team_col=TEAM_COL,
                        pa_col=PA_COL,
                        stat_cols=stat_cols,
                        age_band=1,
                        pa_min=int(PA_MIN_PRED),
                        same_team_only=False,
                        model_name=LLM_MODEL,
                        base_url=OLLAMA_URL,
                    )

                    st.session_state[out_key] = explanation
                    st.session_state[ctx_key] = ctx_used
                    reason_box.markdown(explanation if explanation.strip() else "LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

                except requests.exceptions.ConnectionError:
                    reason_box.error("Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
                except Exception as e:
                    reason_box.error(f"LLM í•´ì„¤ ìƒì„± ì‹¤íŒ¨: {e}")

        if ctx_key in st.session_state:
            with st.expander("LLM ê·¼ê±° JSON(ë””ë²„ê·¸) ë³´ê¸°"):
                st.json(st.session_state[ctx_key])

    st.caption("â€» ì´ ì˜ˆì¸¡ì€ ì°¸ê³ ìš©ì´ë©° ì‹¤ì œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

else:
    st.info("íŒ€/ì„ ìˆ˜/ê¸°ì¤€ë…„ë„ë¥¼ ì„ íƒí•œ ë’¤ 'ë‹¤ìŒ ì‹œì¦Œ ì˜ˆì¸¡í•˜ê¸°'ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
