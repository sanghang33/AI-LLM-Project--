{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94404802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (9731, 39)\n",
      "[Filter] YEAR>=2015 & PA>=223: 9731 -> 1146 (removed 8585)\n",
      "Years in dataset: 2015 ~ 2024\n",
      "Final X/Y: (823, 22) (823, 10)\n",
      "Delta targets: ['AVG_delta', 'RBI_delta', 'HR_delta', 'SB_delta', 'OBP_delta', 'SLG_delta', 'OPS_delta', 'WAR_delta', 'wRC_plus_delta', 'PA_delta']\n",
      "[Split] train < 2023, test >= 2023\n",
      "Train samples: 668 Test samples: 155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m5,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,226</span> (192.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,226\u001b[0m (192.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,458</span> (189.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,458\u001b[0m (189.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - loss: 1168.1985 - mae: 1.2378 - val_loss: 577.6919 - val_mae: 0.8724\n",
      "Epoch 2/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 884.0134 - mae: 1.0862 - val_loss: 561.7021 - val_mae: 0.8591\n",
      "Epoch 3/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 746.3670 - mae: 1.0121 - val_loss: 552.2597 - val_mae: 0.8507\n",
      "Epoch 4/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 695.6172 - mae: 0.9776 - val_loss: 546.2166 - val_mae: 0.8452\n",
      "Epoch 5/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 633.0533 - mae: 0.9344 - val_loss: 543.0385 - val_mae: 0.8428\n",
      "Epoch 6/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 603.0430 - mae: 0.9090 - val_loss: 541.3631 - val_mae: 0.8418\n",
      "Epoch 7/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 576.8894 - mae: 0.8874 - val_loss: 539.5355 - val_mae: 0.8407\n",
      "Epoch 8/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 540.1257 - mae: 0.8658 - val_loss: 537.6196 - val_mae: 0.8394\n",
      "Epoch 9/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 537.9496 - mae: 0.8583 - val_loss: 535.4563 - val_mae: 0.8378\n",
      "Epoch 10/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 502.8086 - mae: 0.8308 - val_loss: 533.5302 - val_mae: 0.8366\n",
      "Epoch 11/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 505.5204 - mae: 0.8341 - val_loss: 531.4123 - val_mae: 0.8348\n",
      "Epoch 12/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 507.4207 - mae: 0.8299 - val_loss: 529.0020 - val_mae: 0.8327\n",
      "Epoch 13/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 472.3475 - mae: 0.8043 - val_loss: 526.5743 - val_mae: 0.8304\n",
      "Epoch 14/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 469.9358 - mae: 0.8012 - val_loss: 523.7902 - val_mae: 0.8275\n",
      "Epoch 15/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 472.0083 - mae: 0.8017 - val_loss: 520.3016 - val_mae: 0.8240\n",
      "Epoch 16/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 468.7747 - mae: 0.7985 - val_loss: 517.7371 - val_mae: 0.8218\n",
      "Epoch 17/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 444.2553 - mae: 0.7777 - val_loss: 517.0748 - val_mae: 0.8219\n",
      "Epoch 18/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 450.4494 - mae: 0.7895 - val_loss: 516.6904 - val_mae: 0.8221\n",
      "Epoch 19/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 431.1867 - mae: 0.7702 - val_loss: 515.9733 - val_mae: 0.8218\n",
      "Epoch 20/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 423.3388 - mae: 0.7540 - val_loss: 515.9533 - val_mae: 0.8225\n",
      "Epoch 21/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 431.8989 - mae: 0.7680 - val_loss: 515.9590 - val_mae: 0.8232\n",
      "Epoch 22/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 423.1030 - mae: 0.7648 - val_loss: 515.8176 - val_mae: 0.8237\n",
      "Epoch 23/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 413.9853 - mae: 0.7520 - val_loss: 514.5253 - val_mae: 0.8231\n",
      "Epoch 24/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 407.2787 - mae: 0.7438 - val_loss: 513.3705 - val_mae: 0.8221\n",
      "Epoch 25/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 400.7546 - mae: 0.7354 - val_loss: 512.8138 - val_mae: 0.8218\n",
      "Epoch 26/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 394.9814 - mae: 0.7299 - val_loss: 512.0892 - val_mae: 0.8212\n",
      "Epoch 27/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 387.7049 - mae: 0.7244 - val_loss: 510.6379 - val_mae: 0.8199\n",
      "Epoch 28/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 405.8768 - mae: 0.7421 - val_loss: 509.4626 - val_mae: 0.8190\n",
      "Epoch 29/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 390.3903 - mae: 0.7282 - val_loss: 508.4970 - val_mae: 0.8184\n",
      "Epoch 30/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 382.3340 - mae: 0.7211 - val_loss: 508.5804 - val_mae: 0.8188\n",
      "Epoch 31/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 378.1396 - mae: 0.7212 - val_loss: 509.0527 - val_mae: 0.8201\n",
      "Epoch 32/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 383.7221 - mae: 0.7246 - val_loss: 509.3946 - val_mae: 0.8210\n",
      "Epoch 33/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 369.7503 - mae: 0.7084 - val_loss: 509.0954 - val_mae: 0.8209\n",
      "Epoch 34/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 373.0025 - mae: 0.7073 - val_loss: 507.9749 - val_mae: 0.8199\n",
      "Epoch 35/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 362.2127 - mae: 0.6961 - val_loss: 506.1412 - val_mae: 0.8180\n",
      "Epoch 36/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 354.2046 - mae: 0.6943 - val_loss: 503.8635 - val_mae: 0.8155\n",
      "Epoch 37/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 353.3303 - mae: 0.6889 - val_loss: 502.0980 - val_mae: 0.8137\n",
      "Epoch 38/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 354.6029 - mae: 0.6984 - val_loss: 501.4345 - val_mae: 0.8131\n",
      "Epoch 39/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 362.0280 - mae: 0.6981 - val_loss: 501.4061 - val_mae: 0.8129\n",
      "Epoch 40/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 352.8575 - mae: 0.6879 - val_loss: 501.1566 - val_mae: 0.8118\n",
      "Epoch 41/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 349.9781 - mae: 0.6880 - val_loss: 501.1819 - val_mae: 0.8109\n",
      "Epoch 42/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 356.4852 - mae: 0.6973 - val_loss: 501.6883 - val_mae: 0.8112\n",
      "Epoch 43/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 345.1267 - mae: 0.6802 - val_loss: 502.5622 - val_mae: 0.8121\n",
      "Epoch 44/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 353.4492 - mae: 0.6944 - val_loss: 503.9083 - val_mae: 0.8136\n",
      "Epoch 45/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 348.5930 - mae: 0.6859 - val_loss: 504.0758 - val_mae: 0.8139\n",
      "Epoch 46/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 335.2756 - mae: 0.6761 - val_loss: 503.7227 - val_mae: 0.8135\n",
      "Epoch 47/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 347.0699 - mae: 0.6887 - val_loss: 501.9058 - val_mae: 0.8116\n",
      "Epoch 48/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 336.0492 - mae: 0.6767 - val_loss: 500.7232 - val_mae: 0.8102\n",
      "Epoch 49/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 341.5648 - mae: 0.6794 - val_loss: 499.5338 - val_mae: 0.8091\n",
      "Epoch 50/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 327.4740 - mae: 0.6583 - val_loss: 498.6700 - val_mae: 0.8084\n",
      "Epoch 51/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 322.7677 - mae: 0.6570 - val_loss: 498.3482 - val_mae: 0.8085\n",
      "Epoch 52/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 333.3830 - mae: 0.6730 - val_loss: 497.6577 - val_mae: 0.8088\n",
      "Epoch 53/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 331.4106 - mae: 0.6709 - val_loss: 496.3003 - val_mae: 0.8081\n",
      "Epoch 54/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 317.7271 - mae: 0.6548 - val_loss: 494.5381 - val_mae: 0.8066\n",
      "Epoch 55/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 325.5348 - mae: 0.6594 - val_loss: 492.7444 - val_mae: 0.8043\n",
      "Epoch 56/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 312.6801 - mae: 0.6475 - val_loss: 490.6006 - val_mae: 0.8024\n",
      "Epoch 57/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 317.9821 - mae: 0.6542 - val_loss: 489.1631 - val_mae: 0.8012\n",
      "Epoch 58/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 321.8041 - mae: 0.6616 - val_loss: 488.6119 - val_mae: 0.8012\n",
      "Epoch 59/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 324.8834 - mae: 0.6622 - val_loss: 487.9192 - val_mae: 0.8007\n",
      "Epoch 60/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 317.1578 - mae: 0.6509 - val_loss: 487.8084 - val_mae: 0.8002\n",
      "Epoch 61/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 304.3290 - mae: 0.6367 - val_loss: 487.4551 - val_mae: 0.7995\n",
      "Epoch 62/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 306.0975 - mae: 0.6353 - val_loss: 486.8855 - val_mae: 0.7986\n",
      "Epoch 63/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 305.6085 - mae: 0.6436 - val_loss: 485.4393 - val_mae: 0.7971\n",
      "Epoch 64/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 308.8245 - mae: 0.6462 - val_loss: 483.7490 - val_mae: 0.7957\n",
      "Epoch 65/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 313.2487 - mae: 0.6465 - val_loss: 482.3009 - val_mae: 0.7948\n",
      "Epoch 66/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 300.4317 - mae: 0.6374 - val_loss: 482.9958 - val_mae: 0.7953\n",
      "Epoch 67/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 308.7859 - mae: 0.6435 - val_loss: 483.9970 - val_mae: 0.7964\n",
      "Epoch 68/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 299.2439 - mae: 0.6377 - val_loss: 484.8155 - val_mae: 0.7976\n",
      "Epoch 69/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 290.1571 - mae: 0.6287 - val_loss: 486.4348 - val_mae: 0.7992\n",
      "Epoch 70/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 297.6439 - mae: 0.6330 - val_loss: 487.4482 - val_mae: 0.8001\n",
      "Epoch 71/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 296.7790 - mae: 0.6338 - val_loss: 487.5114 - val_mae: 0.7999\n",
      "Epoch 72/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 286.1139 - mae: 0.6258 - val_loss: 486.7399 - val_mae: 0.7989\n",
      "Epoch 73/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 296.7085 - mae: 0.6349 - val_loss: 487.0721 - val_mae: 0.7985\n",
      "Epoch 74/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 289.7717 - mae: 0.6235 - val_loss: 488.4299 - val_mae: 0.7989\n",
      "Epoch 75/120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 293.2217 - mae: 0.6284 - val_loss: 488.2224 - val_mae: 0.7982\n",
      "\n",
      "=== Test Metrics (DELTA) ===\n",
      "AVG_delta    | MAE: 0.0248 | RMSE: 0.0305\n",
      "RBI_delta    | MAE: 17.6163 | RMSE: 22.6314\n",
      "HR_delta     | MAE: 5.5462 | RMSE: 7.2674\n",
      "SB_delta     | MAE: 5.2480 | RMSE: 8.1147\n",
      "OBP_delta    | MAE: 0.0243 | RMSE: 0.0305\n",
      "SLG_delta    | MAE: 0.0549 | RMSE: 0.0685\n",
      "OPS_delta    | MAE: 0.0660 | RMSE: 0.0844\n",
      "WAR_delta    | MAE: 1.2416 | RMSE: 1.6894\n",
      "wRC_plus_delta | MAE: 16.8276 | RMSE: 21.4262\n",
      "PA_delta     | MAE: 89.1204 | RMSE: 112.3691\n",
      "\n",
      "=== Test Metrics (RECONSTRUCTED NEXT = current + delta_pred) ===\n",
      "AVG_next     | MAE: 0.0248 | RMSE: 0.0305\n",
      "RBI_next     | MAE: 17.6163 | RMSE: 22.6314\n",
      "HR_next      | MAE: 5.5462 | RMSE: 7.2674\n",
      "SB_next      | MAE: 5.2480 | RMSE: 8.1147\n",
      "OBP_next     | MAE: 0.0243 | RMSE: 0.0305\n",
      "SLG_next     | MAE: 0.0549 | RMSE: 0.0685\n",
      "OPS_next     | MAE: 0.0660 | RMSE: 0.0844\n",
      "WAR_next     | MAE: 1.2416 | RMSE: 1.6894\n",
      "wRC_plus_next | MAE: 16.8276 | RMSE: 21.4262\n",
      "PA_next      | MAE: 89.1204 | RMSE: 112.3691\n",
      "\n",
      "Saved to ./model_kbo/\n",
      "\n",
      "================================================================================\n",
      "[A] FEATURE LIST USED FOR TRAINING (feature_cols)\n",
      "================================================================================\n",
      "Total features: 22\n",
      "  1. Age\n",
      "  2. Age2\n",
      "  3. PA\n",
      "  4. AVG\n",
      "  5. RBI\n",
      "  6. HR\n",
      "  7. SB\n",
      "  8. OBP\n",
      "  9. SLG\n",
      " 10. OPS\n",
      " 11. WAR\n",
      " 12. wRC_plus\n",
      " 13. PA_prev\n",
      " 14. AVG_prev\n",
      " 15. RBI_prev\n",
      " 16. HR_prev\n",
      " 17. SB_prev\n",
      " 18. OBP_prev\n",
      " 19. SLG_prev\n",
      " 20. OPS_prev\n",
      " 21. WAR_prev\n",
      " 22. wRC_plus_prev\n",
      "\n",
      "================================================================================\n",
      "[B] FEATURE MISSING RATE (on training dataframe 'df')\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SB_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OBP_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLG_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPS_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVG_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PA_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WAR_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wRC_plus_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HR_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RBI_prev</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AVG</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RBI</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WAR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wRC_plus</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OBP</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SB</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SLG</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>OPS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  missing_%\n",
       "0         SB_prev       27.1\n",
       "1        OBP_prev       27.1\n",
       "2        SLG_prev       27.1\n",
       "3        OPS_prev       27.1\n",
       "4        AVG_prev       27.1\n",
       "5         PA_prev       27.1\n",
       "6        WAR_prev       27.1\n",
       "7   wRC_plus_prev       27.1\n",
       "8         HR_prev       27.1\n",
       "9        RBI_prev       27.1\n",
       "10           Age2        0.0\n",
       "11            Age        0.0\n",
       "12            AVG        0.0\n",
       "13             PA        0.0\n",
       "14             HR        0.0\n",
       "15            RBI        0.0\n",
       "16            WAR        0.0\n",
       "17       wRC_plus        0.0\n",
       "18            OBP        0.0\n",
       "19             SB        0.0\n",
       "20            SLG        0.0\n",
       "21            OPS        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(참고) 결측 상위 30개만 표시했음. 전체는 missing_df 변수에 있음.\n",
      "\n",
      "================================================================================\n",
      "[C] FEATURE SUMMARY (raw df[feature_cols])\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>823.0</td>\n",
       "      <td>29.629405</td>\n",
       "      <td>4.554612</td>\n",
       "      <td>18.000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>41.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age2</th>\n",
       "      <td>823.0</td>\n",
       "      <td>898.620899</td>\n",
       "      <td>265.845270</td>\n",
       "      <td>324.000</td>\n",
       "      <td>729.00000</td>\n",
       "      <td>900.000</td>\n",
       "      <td>1089.0000</td>\n",
       "      <td>1681.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>823.0</td>\n",
       "      <td>452.001215</td>\n",
       "      <td>116.706491</td>\n",
       "      <td>224.000</td>\n",
       "      <td>363.00000</td>\n",
       "      <td>467.000</td>\n",
       "      <td>543.0000</td>\n",
       "      <td>672.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG</th>\n",
       "      <td>823.0</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.26150</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.3070</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBI</th>\n",
       "      <td>823.0</td>\n",
       "      <td>59.125152</td>\n",
       "      <td>27.316254</td>\n",
       "      <td>8.000</td>\n",
       "      <td>37.50000</td>\n",
       "      <td>55.000</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>146.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>823.0</td>\n",
       "      <td>11.633050</td>\n",
       "      <td>9.634891</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>53.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SB</th>\n",
       "      <td>823.0</td>\n",
       "      <td>8.268530</td>\n",
       "      <td>9.361596</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>60.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBP</th>\n",
       "      <td>823.0</td>\n",
       "      <td>0.357741</td>\n",
       "      <td>0.037544</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.33200</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.3815</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLG</th>\n",
       "      <td>823.0</td>\n",
       "      <td>0.426876</td>\n",
       "      <td>0.083230</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.36800</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPS</th>\n",
       "      <td>823.0</td>\n",
       "      <td>0.784617</td>\n",
       "      <td>0.111507</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.70650</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>1.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR</th>\n",
       "      <td>823.0</td>\n",
       "      <td>2.374058</td>\n",
       "      <td>1.906092</td>\n",
       "      <td>-2.300</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>2.140</td>\n",
       "      <td>3.5250</td>\n",
       "      <td>11.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wRC_plus</th>\n",
       "      <td>823.0</td>\n",
       "      <td>107.633293</td>\n",
       "      <td>28.845890</td>\n",
       "      <td>16.600</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>107.000</td>\n",
       "      <td>126.3000</td>\n",
       "      <td>231.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>464.540000</td>\n",
       "      <td>111.234708</td>\n",
       "      <td>224.000</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>476.500</td>\n",
       "      <td>551.0000</td>\n",
       "      <td>672.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.286113</td>\n",
       "      <td>0.033741</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.26300</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBI_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>60.166667</td>\n",
       "      <td>26.861151</td>\n",
       "      <td>10.000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>56.500</td>\n",
       "      <td>78.2500</td>\n",
       "      <td>146.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>11.781667</td>\n",
       "      <td>9.696083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>53.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SB_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>8.453333</td>\n",
       "      <td>9.261612</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.500</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>60.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBP_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.359642</td>\n",
       "      <td>0.037435</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.33300</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLG_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.428463</td>\n",
       "      <td>0.083159</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.36675</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPS_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>0.788105</td>\n",
       "      <td>0.111812</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.70650</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>1.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAR_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>2.581950</td>\n",
       "      <td>1.879955</td>\n",
       "      <td>-1.570</td>\n",
       "      <td>1.09000</td>\n",
       "      <td>2.395</td>\n",
       "      <td>3.8500</td>\n",
       "      <td>9.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wRC_plus_prev</th>\n",
       "      <td>600.0</td>\n",
       "      <td>109.002500</td>\n",
       "      <td>29.015635</td>\n",
       "      <td>19.100</td>\n",
       "      <td>90.02500</td>\n",
       "      <td>108.150</td>\n",
       "      <td>128.2000</td>\n",
       "      <td>209.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count        mean         std      min        25%      50%  \\\n",
       "Age            823.0   29.629405    4.554612   18.000   27.00000   30.000   \n",
       "Age2           823.0  898.620899  265.845270  324.000  729.00000  900.000   \n",
       "PA             823.0  452.001215  116.706491  224.000  363.00000  467.000   \n",
       "AVG            823.0    0.284100    0.034600    0.181    0.26150    0.283   \n",
       "RBI            823.0   59.125152   27.316254    8.000   37.50000   55.000   \n",
       "HR             823.0   11.633050    9.634891    0.000    4.00000    9.000   \n",
       "SB             823.0    8.268530    9.361596    0.000    2.00000    5.000   \n",
       "OBP            823.0    0.357741    0.037544    0.224    0.33200    0.358   \n",
       "SLG            823.0    0.426876    0.083230    0.221    0.36800    0.419   \n",
       "OPS            823.0    0.784617    0.111507    0.465    0.70650    0.778   \n",
       "WAR            823.0    2.374058    1.906092   -2.300    0.96000    2.140   \n",
       "wRC_plus       823.0  107.633293   28.845890   16.600   88.00000  107.000   \n",
       "PA_prev        600.0  464.540000  111.234708  224.000  390.00000  476.500   \n",
       "AVG_prev       600.0    0.286113    0.033741    0.185    0.26300    0.285   \n",
       "RBI_prev       600.0   60.166667   26.861151   10.000   39.00000   56.500   \n",
       "HR_prev        600.0   11.781667    9.696083    0.000    4.00000    9.000   \n",
       "SB_prev        600.0    8.453333    9.261612    0.000    2.00000    5.500   \n",
       "OBP_prev       600.0    0.359642    0.037435    0.250    0.33300    0.360   \n",
       "SLG_prev       600.0    0.428463    0.083159    0.247    0.36675    0.422   \n",
       "OPS_prev       600.0    0.788105    0.111812    0.508    0.70650    0.779   \n",
       "WAR_prev       600.0    2.581950    1.879955   -1.570    1.09000    2.395   \n",
       "wRC_plus_prev  600.0  109.002500   29.015635   19.100   90.02500  108.150   \n",
       "\n",
       "                     75%       max  \n",
       "Age              33.0000    41.000  \n",
       "Age2           1089.0000  1681.000  \n",
       "PA              543.0000   672.000  \n",
       "AVG               0.3070     0.381  \n",
       "RBI              78.0000   146.000  \n",
       "HR               17.0000    53.000  \n",
       "SB               12.0000    60.000  \n",
       "OBP               0.3815     0.497  \n",
       "SLG               0.4790     0.790  \n",
       "OPS               0.8540     1.287  \n",
       "WAR               3.5250    11.070  \n",
       "wRC_plus        126.3000   231.800  \n",
       "PA_prev         551.0000   672.000  \n",
       "AVG_prev          0.3100     0.376  \n",
       "RBI_prev         78.2500   146.000  \n",
       "HR_prev          18.0000    53.000  \n",
       "SB_prev          12.0000    60.000  \n",
       "OBP_prev          0.3850     0.475  \n",
       "SLG_prev          0.4800     0.718  \n",
       "OPS_prev          0.8630     1.175  \n",
       "WAR_prev          3.8500     9.340  \n",
       "wRC_plus_prev   128.2000   209.800  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(참고) 상위 30개만 표시. 전체는 desc 변수에 있음.\n",
      "\n",
      "================================================================================\n",
      "[D-1] TEST METRICS (DELTA)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OBP_delta</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>0.030454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVG_delta</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.030464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SLG_delta</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.068523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OPS_delta</td>\n",
       "      <td>0.066012</td>\n",
       "      <td>0.084405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WAR_delta</td>\n",
       "      <td>1.241628</td>\n",
       "      <td>1.689364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR_delta</td>\n",
       "      <td>5.546183</td>\n",
       "      <td>7.267376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SB_delta</td>\n",
       "      <td>5.248017</td>\n",
       "      <td>8.114725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wRC_plus_delta</td>\n",
       "      <td>16.827576</td>\n",
       "      <td>21.426238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBI_delta</td>\n",
       "      <td>17.616325</td>\n",
       "      <td>22.631385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PA_delta</td>\n",
       "      <td>89.120407</td>\n",
       "      <td>112.369112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target        MAE        RMSE\n",
       "4       OBP_delta   0.024307    0.030454\n",
       "0       AVG_delta   0.024813    0.030464\n",
       "5       SLG_delta   0.054933    0.068523\n",
       "6       OPS_delta   0.066012    0.084405\n",
       "7       WAR_delta   1.241628    1.689364\n",
       "2        HR_delta   5.546183    7.267376\n",
       "3        SB_delta   5.248017    8.114725\n",
       "8  wRC_plus_delta  16.827576   21.426238\n",
       "1       RBI_delta  17.616325   22.631385\n",
       "9        PA_delta  89.120407  112.369112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELTA avg | MAE: 13.577020102925598 | RMSE: 17.37120463574994\n",
      "\n",
      "================================================================================\n",
      "[D-2] TEST METRICS (NEXT = current + delta_pred)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OBP_next</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>0.030454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVG_next</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>0.030464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SLG_next</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.068523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OPS_next</td>\n",
       "      <td>0.066012</td>\n",
       "      <td>0.084405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WAR_next</td>\n",
       "      <td>1.241628</td>\n",
       "      <td>1.689364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR_next</td>\n",
       "      <td>5.546183</td>\n",
       "      <td>7.267376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SB_next</td>\n",
       "      <td>5.248017</td>\n",
       "      <td>8.114725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wRC_plus_next</td>\n",
       "      <td>16.827574</td>\n",
       "      <td>21.426238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBI_next</td>\n",
       "      <td>17.616325</td>\n",
       "      <td>22.631385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PA_next</td>\n",
       "      <td>89.120407</td>\n",
       "      <td>112.369108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target        MAE        RMSE\n",
       "4       OBP_next   0.024307    0.030454\n",
       "0       AVG_next   0.024813    0.030464\n",
       "5       SLG_next   0.054933    0.068523\n",
       "6       OPS_next   0.066012    0.084405\n",
       "7       WAR_next   1.241628    1.689364\n",
       "2        HR_next   5.546183    7.267376\n",
       "3        SB_next   5.248017    8.114725\n",
       "8  wRC_plus_next  16.827574   21.426238\n",
       "1       RBI_next  17.616325   22.631385\n",
       "9        PA_next  89.120407  112.369108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEXT avg | MAE: 13.577019912935793 | RMSE: 17.371204175162283\n",
      "\n",
      "================================================================================\n",
      "[D-3] BASELINE COMPARISON (baseline: next=current, i.e., delta=0)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>BASE_MAE</th>\n",
       "      <th>MODEL_MAE</th>\n",
       "      <th>MAE_improve_%</th>\n",
       "      <th>BASE_RMSE</th>\n",
       "      <th>MODEL_RMSE</th>\n",
       "      <th>RMSE_improve_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVG_next</td>\n",
       "      <td>0.026684</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>7.012344</td>\n",
       "      <td>0.033368</td>\n",
       "      <td>0.030464</td>\n",
       "      <td>8.704371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OPS_next</td>\n",
       "      <td>0.071342</td>\n",
       "      <td>0.066012</td>\n",
       "      <td>7.470712</td>\n",
       "      <td>0.091828</td>\n",
       "      <td>0.084405</td>\n",
       "      <td>8.084170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PA_next</td>\n",
       "      <td>92.296776</td>\n",
       "      <td>89.120407</td>\n",
       "      <td>3.441473</td>\n",
       "      <td>122.054931</td>\n",
       "      <td>112.369108</td>\n",
       "      <td>7.935626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wRC_plus_next</td>\n",
       "      <td>17.797421</td>\n",
       "      <td>16.827574</td>\n",
       "      <td>5.449367</td>\n",
       "      <td>23.219845</td>\n",
       "      <td>21.426238</td>\n",
       "      <td>7.724456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBI_next</td>\n",
       "      <td>18.658064</td>\n",
       "      <td>17.616325</td>\n",
       "      <td>5.583315</td>\n",
       "      <td>24.219694</td>\n",
       "      <td>22.631385</td>\n",
       "      <td>6.557925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OBP_next</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>0.024307</td>\n",
       "      <td>3.568181</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.030454</td>\n",
       "      <td>6.297390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR_next</td>\n",
       "      <td>5.406452</td>\n",
       "      <td>5.546183</td>\n",
       "      <td>-2.584522</td>\n",
       "      <td>7.427933</td>\n",
       "      <td>7.267376</td>\n",
       "      <td>2.161535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SB_next</td>\n",
       "      <td>5.367742</td>\n",
       "      <td>5.248017</td>\n",
       "      <td>2.230458</td>\n",
       "      <td>8.257157</td>\n",
       "      <td>8.114725</td>\n",
       "      <td>1.724957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WAR_next</td>\n",
       "      <td>1.321742</td>\n",
       "      <td>1.241628</td>\n",
       "      <td>6.061217</td>\n",
       "      <td>1.716650</td>\n",
       "      <td>1.689364</td>\n",
       "      <td>1.589479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SLG_next</td>\n",
       "      <td>0.052368</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>-4.898894</td>\n",
       "      <td>0.067452</td>\n",
       "      <td>0.068523</td>\n",
       "      <td>-1.589000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target   BASE_MAE  MODEL_MAE  MAE_improve_%   BASE_RMSE  MODEL_RMSE  \\\n",
       "0       AVG_next   0.026684   0.024813       7.012344    0.033368    0.030464   \n",
       "6       OPS_next   0.071342   0.066012       7.470712    0.091828    0.084405   \n",
       "9        PA_next  92.296776  89.120407       3.441473  122.054931  112.369108   \n",
       "8  wRC_plus_next  17.797421  16.827574       5.449367   23.219845   21.426238   \n",
       "1       RBI_next  18.658064  17.616325       5.583315   24.219694   22.631385   \n",
       "4       OBP_next   0.025206   0.024307       3.568181    0.032501    0.030454   \n",
       "2        HR_next   5.406452   5.546183      -2.584522    7.427933    7.267376   \n",
       "3        SB_next   5.367742   5.248017       2.230458    8.257157    8.114725   \n",
       "7       WAR_next   1.321742   1.241628       6.061217    1.716650    1.689364   \n",
       "5       SLG_next   0.052368   0.054933      -4.898894    0.067452    0.068523   \n",
       "\n",
       "   RMSE_improve_%  \n",
       "0        8.704371  \n",
       "6        8.084170  \n",
       "9        7.935626  \n",
       "8        7.724456  \n",
       "1        6.557925  \n",
       "4        6.297390  \n",
       "2        2.161535  \n",
       "3        1.724957  \n",
       "7        1.589479  \n",
       "5       -1.589000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary (mean improvement):\n",
      "MAE improvement %: 3.333365089912436\n",
      "RMSE improvement %: 4.919090818197706\n",
      "\n",
      "✅ 리포트 끝! (feature_cols / 결측 / 요약통계 / DELTA&NEXT 성능 / baseline 비교)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "[이유찬 12894] 2024 ACTUAL  →  2025 PREDICTED  →  2025 ACTUAL\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>AVG</th>\n",
       "      <th>RBI</th>\n",
       "      <th>HR</th>\n",
       "      <th>SB</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>WAR</th>\n",
       "      <th>wRC_plus</th>\n",
       "      <th>PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.277</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.705</td>\n",
       "      <td>1.04</td>\n",
       "      <td>87.9</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type  Year    AVG   RBI   HR    SB    OBP    SLG    OPS   WAR  wRC_plus  \\\n",
       "0  ACTUAL  2024  0.277  23.0  3.0  16.0  0.341  0.364  0.705  1.04      87.9   \n",
       "\n",
       "      PA  \n",
       "0  262.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>AVG</th>\n",
       "      <th>RBI</th>\n",
       "      <th>HR</th>\n",
       "      <th>SB</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>WAR</th>\n",
       "      <th>wRC_plus</th>\n",
       "      <th>PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREDICTED</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.268332</td>\n",
       "      <td>25.048622</td>\n",
       "      <td>4.403632</td>\n",
       "      <td>13.916182</td>\n",
       "      <td>0.338771</td>\n",
       "      <td>0.343291</td>\n",
       "      <td>0.692176</td>\n",
       "      <td>0.745311</td>\n",
       "      <td>85.69809</td>\n",
       "      <td>289.828339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type  Year       AVG        RBI        HR         SB       OBP  \\\n",
       "0  PREDICTED  2025  0.268332  25.048622  4.403632  13.916182  0.338771   \n",
       "\n",
       "        SLG       OPS       WAR  wRC_plus          PA  \n",
       "0  0.343291  0.692176  0.745311  85.69809  289.828339  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>AVG</th>\n",
       "      <th>RBI</th>\n",
       "      <th>HR</th>\n",
       "      <th>SB</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>WAR</th>\n",
       "      <th>wRC_plus</th>\n",
       "      <th>PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACTUAL</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.242</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.84</td>\n",
       "      <td>79.0</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type  Year    AVG   RBI   HR    SB    OBP   SLG    OPS   WAR  wRC_plus  \\\n",
       "0  ACTUAL  2025  0.242  16.0  1.0  12.0  0.328  0.29  0.618  0.84      79.0   \n",
       "\n",
       "      PA  \n",
       "0  311.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# KBO Next Season Prediction (Deep Learning MLP) - DELTA MODEL (FINAL)\n",
    "# ✅ 2015년 이후만 사용\n",
    "# ✅ t시즌 PA >= 223 (입력 안정화)\n",
    "# ✅ 타깃은 \"다음시즌 절대값\"이 아니라 \"증감(Δ = next - current)\" 예측\n",
    "# ✅ 예측 시: next_pred = current + delta_pred\n",
    "# ✅ 저장: model_kbo/ (app에서 로드 가능)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# -------------------------\n",
    "# 0) Seed / Path\n",
    "# -------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "CSV_PATH = r\"C:\\Users\\yusan\\OneDrive\\Desktop\\2025 winter\\Notebook\\Colab Notebooks\\dataset\\kbo_batting_stats.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) Config\n",
    "# -------------------------\n",
    "ID_COL   = \"Id\"\n",
    "YEAR_COL = \"Year\"\n",
    "AGE_COL  = \"Age\"\n",
    "PA_COL   = \"PA\"\n",
    "\n",
    "TRAIN_MIN_YEAR = 2015\n",
    "PA_MIN_T       = 223\n",
    "\n",
    "#타겟 \n",
    "TARGETS = [\"AVG\", \"RBI\", \"HR\", \"SB\", \"OBP\", \"SLG\", \"OPS\", \"WAR\", \"wRC_plus\"]\n",
    "\n",
    "# 데이터 로드\n",
    "df0 = pd.read_csv(CSV_PATH)\n",
    "print(\"Loaded:\", df0.shape)\n",
    "\n",
    "# 컬럼명 안전 처리\n",
    "df0 = df0.rename(columns={\"wRC+\": \"wRC_plus\"})\n",
    "\n",
    "# 필수 컬럼 체크\n",
    "required = [ID_COL, YEAR_COL, AGE_COL, PA_COL] + TARGETS\n",
    "missing_req = [c for c in required if c not in df0.columns]\n",
    "if missing_req:\n",
    "    raise ValueError(f\"필수 컬럼이 없습니다: {missing_req}\\n현재 컬럼: {list(df0.columns)}\")\n",
    "\n",
    "# Numeric 변환 + 정렬\n",
    "df0[YEAR_COL] = pd.to_numeric(df0[YEAR_COL], errors=\"coerce\")\n",
    "df0[AGE_COL]  = pd.to_numeric(df0[AGE_COL], errors=\"coerce\")\n",
    "df0[PA_COL]   = pd.to_numeric(df0[PA_COL], errors=\"coerce\")\n",
    "\n",
    "for t in TARGETS:\n",
    "    df0[t] = pd.to_numeric(df0[t], errors=\"coerce\")\n",
    "\n",
    "df0 = df0.dropna(subset=[ID_COL, YEAR_COL, AGE_COL, PA_COL]).copy()\n",
    "df0 = df0.sort_values([ID_COL, YEAR_COL]).reset_index(drop=True)\n",
    "\n",
    "# 시즌 기준 필터링\n",
    "before = len(df0)\n",
    "df0 = df0[(df0[YEAR_COL] >= TRAIN_MIN_YEAR) & (df0[PA_COL] >= PA_MIN_T)].copy()\n",
    "after = len(df0)\n",
    "print(f\"[Filter] YEAR>={TRAIN_MIN_YEAR} & PA>={PA_MIN_T}: {before} -> {after} (removed {before-after})\")\n",
    "\n",
    "# 예측값 만들기 \n",
    "df0[f\"{PA_COL}_next\"] = df0.groupby(ID_COL)[PA_COL].shift(-1)\n",
    "df0[f\"{YEAR_COL}_next\"] = df0.groupby(ID_COL)[YEAR_COL].shift(-1)\n",
    "\n",
    "for t in TARGETS:\n",
    "    df0[f\"{t}_next\"] = df0.groupby(ID_COL)[t].shift(-1)\n",
    "\n",
    "# prev을 통한 보조 feature 생성\n",
    "df0[f\"{PA_COL}_prev\"] = df0.groupby(ID_COL)[PA_COL].shift(1)\n",
    "for t in TARGETS:\n",
    "    df0[f\"{t}_prev\"] = df0.groupby(ID_COL)[t].shift(1)\n",
    "\n",
    "# 학습 샘플 구성 \n",
    "need_next = [f\"{t}_next\" for t in TARGETS] + [f\"{PA_COL}_next\"]\n",
    "df = df0.dropna(subset=need_next + [YEAR_COL, AGE_COL, PA_COL]).copy()\n",
    "\n",
    "# 숫자형 강제 + 결측 정리\n",
    "for c in TARGETS + [f\"{t}_next\" for t in TARGETS] + [PA_COL, f\"{PA_COL}_next\", f\"{PA_COL}_prev\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=TARGETS + [f\"{t}_next\" for t in TARGETS] + [PA_COL, f\"{PA_COL}_next\"]).copy()\n",
    "\n",
    "print(\"Years in dataset:\", int(df[YEAR_COL].min()), \"~\", int(df[YEAR_COL].max()))\n",
    "\n",
    "# Δ 타깃 만들기\n",
    "for t in TARGETS:\n",
    "    df[f\"{t}_delta\"] = df[f\"{t}_next\"] - df[t]\n",
    "\n",
    "df[f\"{PA_COL}_delta\"] = df[f\"{PA_COL}_next\"] - df[PA_COL]  # 참고용(출장 증감)\n",
    "\n",
    "DELTA_TARGETS = [f\"{t}_delta\" for t in TARGETS] + [f\"{PA_COL}_delta\"]\n",
    "\n",
    "# Feature 구성\n",
    "#    - 나이(에이징), 이번 시즌 스탯, PA, (prev 스탯/PA는 보조)\n",
    "df[\"Age2\"] = df[AGE_COL] ** 2\n",
    "\n",
    "feature_cols = (\n",
    "    [AGE_COL, \"Age2\", PA_COL]\n",
    "    + TARGETS\n",
    "    + [f\"{PA_COL}_prev\"] + [f\"{t}_prev\" for t in TARGETS]\n",
    ")\n",
    "\n",
    "X = df[feature_cols].values.astype(\"float32\")\n",
    "Y = df[DELTA_TARGETS].values.astype(\"float32\")\n",
    "\n",
    "print(\"Final X/Y:\", X.shape, Y.shape)\n",
    "print(\"Delta targets:\", DELTA_TARGETS)\n",
    "\n",
    "# Time-based split (마지막 2년 test, 부족하면 자동 확장)\n",
    "years_sorted = np.array(sorted(df[YEAR_COL].dropna().unique()))\n",
    "max_year = int(years_sorted.max())\n",
    "\n",
    "def make_split(_df, start_test_year):\n",
    "    train_mask = (_df[YEAR_COL] < start_test_year)\n",
    "    test_mask  = (_df[YEAR_COL] >= start_test_year)\n",
    "    return train_mask, test_mask\n",
    "\n",
    "start_test_year = max_year - 1\n",
    "for _ in range(6):\n",
    "    train_mask, test_mask = make_split(df, start_test_year)\n",
    "    if train_mask.sum() > 0 and test_mask.sum() > 0:\n",
    "        break\n",
    "    start_test_year -= 1\n",
    "\n",
    "print(f\"[Split] train < {start_test_year}, test >= {start_test_year}\")\n",
    "print(\"Train samples:\", int(train_mask.sum()), \"Test samples:\", int(test_mask.sum()))\n",
    "if train_mask.sum() == 0 or test_mask.sum() == 0:\n",
    "    raise ValueError(\"train/test 분할 실패: 필터가 너무 강함. PA나 연도 기준을 완화하세요.\")\n",
    "\n",
    "X_train, Y_train = X[train_mask], Y[train_mask]\n",
    "X_test,  Y_test  = X[test_mask],  Y[test_mask]\n",
    "\n",
    "# Impute + Scale (X/Y 분리)\n",
    "x_imputer = SimpleImputer(strategy=\"median\")\n",
    "x_scaler  = StandardScaler()\n",
    "\n",
    "y_scaler  = StandardScaler() \n",
    "\n",
    "X_train_s = x_scaler.fit_transform(x_imputer.fit_transform(X_train)).astype(\"float32\")\n",
    "X_test_s  = x_scaler.transform(x_imputer.transform(X_test)).astype(\"float32\")\n",
    "\n",
    "Y_train_s = y_scaler.fit_transform(Y_train).astype(\"float32\")\n",
    "Y_test_s  = y_scaler.transform(Y_test).astype(\"float32\")\n",
    "\n",
    "# MLP 빌드\n",
    "def build_mlp(n_features, n_targets):\n",
    "    inputs = keras.Input(shape=(n_features,))\n",
    "    x = layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.20)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.10)(x)\n",
    "\n",
    "    outputs = layers.Dense(n_targets, activation=\"linear\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_mlp(X_train_s.shape[1], Y_train_s.shape[1])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 샘플 가중치: PA 큰 시즌을 더 신뢰 (노이즈 완화)\n",
    "sample_weight = df.loc[train_mask, PA_COL].values.astype(\"float32\")\n",
    "sample_weight = np.clip(sample_weight, 1.0, None)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_s, Y_train_s,\n",
    "    sample_weight=sample_weight,\n",
    "    validation_split=0.2,\n",
    "    epochs=120,\n",
    "    batch_size=256,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 12) 학습 평가\n",
    "pred_delta_s = model.predict(X_test_s, verbose=0)\n",
    "pred_delta   = y_scaler.inverse_transform(pred_delta_s)\n",
    "true_delta   = y_scaler.inverse_transform(Y_test_s)\n",
    "\n",
    "print(\"\\n=== Test Metrics (DELTA) ===\")\n",
    "for i, col in enumerate(DELTA_TARGETS):\n",
    "    mae  = mean_absolute_error(true_delta[:, i], pred_delta[:, i])\n",
    "    rmse = float(np.sqrt(mean_squared_error(true_delta[:, i], pred_delta[:, i])))\n",
    "    print(f\"{col:12s} | MAE: {mae:.4f} | RMSE: {rmse:.4f}\")\n",
    "\n",
    "# 현재값(current) = df의 test rows에서 가져옴\n",
    "df_test = df.loc[test_mask].copy()\n",
    "\n",
    "# current matrix (TARGETS + PA)\n",
    "current_cols = TARGETS + [PA_COL]\n",
    "current = df_test[current_cols].values.astype(\"float32\")\n",
    "\n",
    "# true next matrix\n",
    "true_next_cols = [f\"{t}_next\" for t in TARGETS] + [f\"{PA_COL}_next\"]\n",
    "true_next = df_test[true_next_cols].values.astype(\"float32\")\n",
    "\n",
    "# pred next = current + pred_delta\n",
    "pred_next = current + pred_delta  \n",
    "\n",
    "print(\"\\n=== Test Metrics (RECONSTRUCTED NEXT = current + delta_pred) ===\")\n",
    "next_names = [f\"{t}_next\" for t in TARGETS] + [f\"{PA_COL}_next\"]\n",
    "for i, name in enumerate(next_names):\n",
    "    mae  = mean_absolute_error(true_next[:, i], pred_next[:, i])\n",
    "    rmse = float(np.sqrt(mean_squared_error(true_next[:, i], pred_next[:, i])))\n",
    "    print(f\"{name:12s} | MAE: {mae:.4f} | RMSE: {rmse:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 13) Save bundle (앱에서 사용)\n",
    "# -------------------------\n",
    "os.makedirs(\"model_kbo\", exist_ok=True)\n",
    "\n",
    "model.save(\"model_kbo/kbo_mlp.keras\")\n",
    "joblib.dump(x_imputer, \"model_kbo/imputer.pkl\")\n",
    "joblib.dump(x_scaler,  \"model_kbo/x_scaler.pkl\")\n",
    "joblib.dump(y_scaler,  \"model_kbo/y_scaler.pkl\")\n",
    "\n",
    "joblib.dump(feature_cols, \"model_kbo/feature_cols.pkl\")\n",
    "\n",
    "joblib.dump(next_names, \"model_kbo/targets.pkl\")\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"mode\": \"delta\",\n",
    "        \"train_min_year\": TRAIN_MIN_YEAR,\n",
    "        \"pa_min_t\": PA_MIN_T,\n",
    "        \"split_start_test_year\": int(start_test_year),\n",
    "        \"targets\": TARGETS,\n",
    "        \"delta_targets\": DELTA_TARGETS,\n",
    "        \"current_cols\": current_cols,\n",
    "        \"next_names\": next_names,\n",
    "        \"note\": \"Model predicts deltas. At inference: next_pred = current + delta_pred.\",\n",
    "    },\n",
    "    \"model_kbo/meta.pkl\"\n",
    ")\n",
    "\n",
    "print(\"\\nSaved to ./model_kbo/\")\n",
    "\n",
    "# Inference helper (노트북에서 바로 확인용)\n",
    "def predict_next_for_player(player_id, base_year=2025):\n",
    "    row = df0[(df0[ID_COL] == player_id) & (df0[YEAR_COL].astype(int) == int(base_year))].copy()\n",
    "    if len(row) != 1:\n",
    "        raise ValueError(f\"player_id={player_id}, year={base_year} 행을 1개로 찾지 못함 (찾은 개수={len(row)})\")\n",
    "\n",
    "    # 파생: Age2\n",
    "    row[\"Age2\"] = row[AGE_COL].astype(float) ** 2\n",
    "\n",
    "    prev = df0[(df0[ID_COL] == player_id) & (df0[YEAR_COL].astype(int) == int(base_year) - 1)].copy()\n",
    "    if len(prev) == 1:\n",
    "        row[f\"{PA_COL}_prev\"] = float(prev.iloc[0][PA_COL])\n",
    "        for t in TARGETS:\n",
    "            row[f\"{t}_prev\"] = float(prev.iloc[0][t])\n",
    "    else:\n",
    "        row[f\"{PA_COL}_prev\"] = np.nan\n",
    "        for t in TARGETS:\n",
    "            row[f\"{t}_prev\"] = np.nan\n",
    "\n",
    "    x_raw = row[feature_cols].values.astype(\"float32\")\n",
    "    x_raw = np.nan_to_num(x_raw, nan=np.nan)\n",
    "\n",
    "    x_s = x_scaler.transform(x_imputer.transform(x_raw)).astype(\"float32\")\n",
    "    delta_s = model.predict(x_s, verbose=0)\n",
    "    delta = y_scaler.inverse_transform(delta_s)[0]  # (targets_delta + PA_delta)\n",
    "\n",
    "    # current\n",
    "    cur = np.array([float(row.iloc[0][c]) for c in current_cols], dtype=\"float32\")\n",
    "\n",
    "    next_pred = cur + delta\n",
    "\n",
    "    # 결과 dict\n",
    "    out = {}\n",
    "    for i, t in enumerate(TARGETS):\n",
    "        out[f\"{t}_next_pred\"] = float(next_pred[i])\n",
    "        out[f\"{t}_delta_pred\"] = float(delta[i])\n",
    "\n",
    "    out[f\"{PA_COL}_next_pred\"] = float(max(0.0, next_pred[-1]))\n",
    "    out[f\"{PA_COL}_delta_pred\"] = float(delta[-1])\n",
    "\n",
    "    return out\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[A] FEATURE LIST USED FOR TRAINING (feature_cols)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "for i, c in enumerate(feature_cols, 1):\n",
    "    print(f\"{i:3d}. {c}\")\n",
    "\n",
    "# feature 결측률도 확인 (데이터 품질 체크)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[B] FEATURE MISSING RATE (on training dataframe 'df')\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_rate = (df[feature_cols].isna().mean().sort_values(ascending=False) * 100).round(2)\n",
    "missing_df = missing_rate.reset_index()\n",
    "missing_df.columns = [\"feature\", \"missing_%\"]\n",
    "display(missing_df.head(30))  # 결측 많은 상위 30개\n",
    "print(\"\\n(참고) 결측 상위 30개만 표시했음. 전체는 missing_df 변수에 있음.\")\n",
    "\n",
    "# 표준화 전(원본) 분포 간단 요약도 같이\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[C] FEATURE SUMMARY (raw df[feature_cols])\")\n",
    "print(\"=\"*80)\n",
    "desc = df[feature_cols].describe().T\n",
    "display(desc[[\"count\",\"mean\",\"std\",\"min\",\"25%\",\"50%\",\"75%\",\"max\"]].head(30))\n",
    "print(\"\\n(참고) 상위 30개만 표시. 전체는 desc 변수에 있음.\")\n",
    "\n",
    "# =========================================================\n",
    "# [D] EVALUATION SUMMARY TABLES\n",
    "#   - 1) DELTA 성능 (모델이 직접 예측한 값)\n",
    "#   - 2) NEXT 성능 (current + delta_pred)\n",
    "#   - 3) BASELINE 비교 (delta=0, 즉 next=current)\n",
    "# =========================================================\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "required_vars = [\"pred_delta\", \"true_delta\", \"pred_next\", \"true_next\", \"DELTA_TARGETS\", \"next_names\", \"current\"]\n",
    "missing_vars = [v for v in required_vars if v not in globals()]\n",
    "if missing_vars:\n",
    "    raise NameError(f\"아래 변수가 없어서 요약 리포트 생성 불가: {missing_vars}\\n\"\n",
    "                    f\"-> 12) Evaluate 셀이 먼저 실행되어야 함.\")\n",
    "\n",
    "# 1) DELTA metrics table\n",
    "rows = []\n",
    "for i, name in enumerate(DELTA_TARGETS):\n",
    "    y_t = true_delta[:, i]\n",
    "    y_p = pred_delta[:, i]\n",
    "    rows.append({\n",
    "        \"target\": name,\n",
    "        \"MAE\": float(mean_absolute_error(y_t, y_p)),\n",
    "        \"RMSE\": rmse(y_t, y_p),\n",
    "    })\n",
    "delta_metrics_df = pd.DataFrame(rows).sort_values(\"RMSE\", ascending=True)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[D-1] TEST METRICS (DELTA)\")\n",
    "print(\"=\"*80)\n",
    "display(delta_metrics_df)\n",
    "print(\"DELTA avg | MAE:\", float(delta_metrics_df[\"MAE\"].mean()), \"| RMSE:\", float(delta_metrics_df[\"RMSE\"].mean()))\n",
    "\n",
    "# 2) NEXT metrics table (reconstructed)\n",
    "rows = []\n",
    "for i, name in enumerate(next_names):\n",
    "    y_t = true_next[:, i]\n",
    "    y_p = pred_next[:, i]\n",
    "    rows.append({\n",
    "        \"target\": name,\n",
    "        \"MAE\": float(mean_absolute_error(y_t, y_p)),\n",
    "        \"RMSE\": rmse(y_t, y_p),\n",
    "    })\n",
    "next_metrics_df = pd.DataFrame(rows).sort_values(\"RMSE\", ascending=True)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[D-2] TEST METRICS (NEXT = current + delta_pred)\")\n",
    "print(\"=\"*80)\n",
    "display(next_metrics_df)\n",
    "print(\"NEXT avg | MAE:\", float(next_metrics_df[\"MAE\"].mean()), \"| RMSE:\", float(next_metrics_df[\"RMSE\"].mean()))\n",
    "\n",
    "# 3) BASELINE: delta=0 -> next_pred_baseline = current\n",
    "# (즉, \"내년은 올해랑 같다\"라는 가장 단순한 기준)\n",
    "baseline_pred_next = current.copy()\n",
    "\n",
    "rows = []\n",
    "for i, name in enumerate(next_names):\n",
    "    y_t = true_next[:, i]\n",
    "    y_base = baseline_pred_next[:, i]\n",
    "    y_model = pred_next[:, i]\n",
    "\n",
    "    base_mae = float(mean_absolute_error(y_t, y_base))\n",
    "    base_rmse = rmse(y_t, y_base)\n",
    "    model_mae = float(mean_absolute_error(y_t, y_model))\n",
    "    model_rmse = rmse(y_t, y_model)\n",
    "\n",
    "    rows.append({\n",
    "        \"target\": name,\n",
    "        \"BASE_MAE\": base_mae,\n",
    "        \"MODEL_MAE\": model_mae,\n",
    "        \"MAE_improve_%\": float((base_mae - model_mae) / base_mae * 100) if base_mae != 0 else np.nan,\n",
    "        \"BASE_RMSE\": base_rmse,\n",
    "        \"MODEL_RMSE\": model_rmse,\n",
    "        \"RMSE_improve_%\": float((base_rmse - model_rmse) / base_rmse * 100) if base_rmse != 0 else np.nan,\n",
    "    })\n",
    "\n",
    "baseline_df = pd.DataFrame(rows)\n",
    "baseline_df = baseline_df.sort_values(\"RMSE_improve_%\", ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[D-3] BASELINE COMPARISON (baseline: next=current, i.e., delta=0)\")\n",
    "print(\"=\"*80)\n",
    "display(baseline_df)\n",
    "\n",
    "print(\"\\nSummary (mean improvement):\")\n",
    "print(\"MAE improvement %:\", float(baseline_df[\"MAE_improve_%\"].mean()))\n",
    "print(\"RMSE improvement %:\", float(baseline_df[\"RMSE_improve_%\"].mean()))\n",
    "\n",
    "print(\"\\n✅ 리포트 끝! (feature_cols / 결측 / 요약통계 / DELTA&NEXT 성능 / baseline 비교)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
